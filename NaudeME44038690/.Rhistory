df
df<- data.frame(
grp= c(0,0,0,0,1,1,1,1,2,2,2,2),
deltabp= c(5,0.5,-1.2,2,18,28,14,23,-50,-24,-38,-40)
)
df
summary(df)
tapply(df$deltabp,df$grp,mean)
tapply(df$deltabp,df$grp,mean)
tapply(df$deltabp,df$grp,sd)
tapply(df$deltabp,df$grp,median)
plot(df$deltabp~factor(df$grp))
aov(deltabp~grp)
aov(deltabp~grp,data=df)
myaov<-aov(deltabp~grp,data=df)
myaov[]
summary(myaov)
anova(myaov)
myaov<-aov(deltabp~factor(grp),data=df)
myaov
summary(myaov)
pairwise.t.test(df$deltabp,df$grp,method="bonf")
pairwise.t.test(df$deltabp,df$grp,"bonf")
TukeyHSD(myaov)
myaov<-aov(deltabp~factor(grp),data=df)
TukeyHSD(myaov)
shapiro.test(myaov$residuals)
plot(myaov$residuals~factor(df$grp))
plot(density(myaov$residuals))
e<- myaov$residuals
qqnorm(e)
qqline(e)
plot(de)
de<- density(e)
plot(de)
lines(de$x,dnorm(de$x,mean(e),sd(e)))
plot(de)
lines(de$x,dnorm(de$x,mean(e),sd(e)),col="cornflowerblue",lwd=2,lty=2)
df<- data.frame(
grp= c(0,0,0,0,1,1,1,1,2,2,2,2),
deltabp= c(5,0.5,-1.2,2,18,28,14,23,-50,-24,-38,-40)
)
myaov<-aov(deltabp~factor(grp),data=df)
tapply(df$deltabp,df$grp,var)
bartlett.test(myaov)
bartlett.test(df$deltabp~factor(grp))
car::leveneTest
car::leveneTest(df$deltabp,factor(grp))
car::leveneTest(df$deltabp,factor(df$grp))
kruskal.test(df$deltabp~factor(df$grp))
install.packages("rstatix")
rstatix::pairwise_wilcoxon_test(df$deltabp~grp,data=df,p.adjust.method= "bonf")
rstatix::pairwise_wilcox_test(df$deltabp~grp,data=df,p.adjust.method= "bonf")
rstatix::pairwise_wilcox_test(deltabp~grp,data=df,p.adjust.method= "bonf")
rstatix::pairwise_wilcox_test(deltabp~grp,data=df,p.adjust.method= "hochberg")
dd<- data.frame(
Y=    c(25,13,20,15,11,14,10,12,12,13,9,10),
drug= c(0,0,0,0,1,1,1,1,2,2,2,2),
ex=   c(0,0,1,1,0,0,1,1,0,0,1,1)
)
dd
interaction.plot(dd$drug,dd$ex,dd$Y)
interaction.plot(dd$ex,dd$drug,dd$Y)
interaction.plot(dd$drug,dd$ex,dd$Y)
aov(Y~drug+ex+drug:ex,data=dd)
myaov2<-aov(Y~drug*ex,data=dd)
myaov2
anova(myaov2)
myaov2<-aov(Y~factor(drug)+factor(ex)+factor(drug):factor(ex),data=dd)
anova(myaov2)
plot(dd$Y~factor(paste(dd$,dd$ex)))
plot(dd$Y~factor(paste(dd$drug,dd$ex)))
dd<- data.frame(Y=1:13,
A= c(0,0,0,0,0,1,1,1,1,2,2,2,2),
B= c(0,0,1,1,1,0,0,1,1,0,0,0,1))
aov(Y~factor(A)*factor(B),data=dd)
an1<-aov(Y~factor(A)*factor(B),data=dd)
anova(an1)
library("car")
options(contrasts=c("constr.sum","contr.poly"))
library("car")
options(contrasts=c("constr.sum","contr.poly"))
an1<-aov(Y~factor(A)*factor(B),data=dd)
library("car")
options(contrasts=c("constr.sum","contr.poly"))
an1<-aov(Y~factor(A)*factor(B),data=dd)
library("car")
options(contrasts=c("contr.sum","contr.poly"))
an1<-aov(Y~factor(A)*factor(B),data=dd)
Anova(an1,type="II")
Anova(an1,type="III")
options(contrasts=c("contr.treatment","contr.poly"))
dd<- data.frame(Y=1:6,7:1,
A= c(0,0,0,0,0,1,1,1,1,2,2,2,2),
B= c(0,0,1,1,1,0,0,1,1,0,0,0,1))
dd<- data.frame(Y=c(1:6,7:1),
A= c(0,0,0,0,0,1,1,1,1,2,2,2,2),
B= c(0,0,1,1,1,0,0,1,1,0,0,0,1))
an1<-aov(Y~factor(A)*factor(B),data=dd)
anova(an1)
TukeyHSD(an1)
interaction.plot(dd$A,dd$B,dd$Y)
table(dd$A,dd$B)
r<- an1$residuals
shapiro.test(r)
qqnorm(r)
qqnorm(r)
qqline(r)
AB<-paste0(dd$A,dd$B)
bartlett.test(dd$Y,AB)
car::leveneTest(dd$Y,AB)
car::leveneTest(dd$Y,factor(AB))
plot(r,factor(AB))
plot(r~factor(AB))
rm(list = ls())
cat("\014")
Integration_CI<- function(N,B,alpha){
x<- numeric(B)
for(i in 1:B){
var<- runif(N,0,2*pi)
func<- sin(var)^2
x[i]<- mean(func)
}
x<- sort(x)
lowerbound<- x[B*(alpha/2)]
upperbound<- x[B*(1-alpha/2)]
return(c(lowerbound,upperbound))
}
A = Integration_CI(50,1000,0.05)
A
B = Integration_CI(100,100,0.1)
B
C = Integration_CI(5000,200,0.01)
C
lambda1<- -0.5
Y1<-c(12, 4, 8, 13, 10)
lambda2<- 1
Y2<- c(-22, 34, 23, -9, 3)
scaleboxCox<- function(Y,lambda){
n<- length(Y)
yprime<- numeric(Y)
K<- 1
for(i in 1:n){
K<- K*Y[i]
}
K<- K^(1/n)
if(lambda==0){
for(j in 1:n){
yprime[j]<- K*log(Y[i])
}
}else{
for(k in 1:n){
yprime[k]<- (Y[i]^lambda -1)/(lambda*K^(lambda -1))
}
}
return(yprime)
}
scaleboxCox(Y1,lambda1)
scaleboxCox<- function(Y,lambda){
n<- length(Y)
yprime<- numeric(length(Y))
K<- 1
for(i in 1:n){
K<- K*Y[i]
}
K<- K^(1/n)
if(lambda==0){
for(j in 1:n){
yprime[j]<- K*log(Y[i])
}
}else{
for(k in 1:n){
yprime[k]<- (Y[i]^lambda -1)/(lambda*K^(lambda -1))
}
}
return(yprime)
}
scaleboxCox(Y1,lambda1)
scaleboxCox<- function(Y,lambda){
n<- length(Y)
yprime<- numeric(length(Y))
K<- 1
for(i in 1:n){
K<- K*Y[i]
}
K<- K^(1/n)
if(lambda==0){
for(j in 1:n){
yprime[j]<- K*log(Y[i])
}
}else{
for(k in 1:n){
yprime[k]<- (Y[k]^lambda -1)/(lambda*K^(lambda -1))
}
}
return(yprime)
}
scaleboxCox(Y1,lambda1)
scaleboxCox<- function(Y,lambda){
n<- length(Y)
yprime<- numeric(length(Y))
K<- 1
for(i in 1:n){
K<- K*Y[i]
}
K<- K^(1/n)
if(lambda==0){
for(j in 1:n){
yprime[j]<- K*log(Y[j])
}
}else{
for(k in 1:n){
yprime[k]<- (Y[k]^lambda -1)/(lambda*K^(lambda -1))
}
}
return(yprime)
}
scaleboxCox(Y1,lambda1)
scaleboxCox<- function(Y,lambda){
n<- length(Y)
yprime<- numeric(length(Y))
K<- 1
for(i in 1:n){
K<- K*Y[i]
}
K<- K^(1/n)
if(lambda==0){
for(j in 1:n){
yprime[j]<- K*log(Y[j])
}
}else{
for(k in 1:n){
yprime[k]<- (Y[k]^lambda -1)/(lambda*K^(lambda -1))
}
}
return(yprime)
}
scaleboxCox(Y1,lambda1)
my_chol<- function(df,stat){
n<- nrow(df)
total<- numeric(nrow(df))
ratio<- numeric(nrow(df))
risk<- character(nrow(df))
for (i in 1:n){
total[i]<- df$hdl[i]+df$ldl[i] +0.2*df$trigl[i]
ratio[i]<- total[i]/df$hdl[i]
if (ratio[i] > 5){
risk[i]<- "High risk"
}
else{
risk[i]<- "Average risk"
}
}
totalHighRisk<- nrow(subset(risk, category= "High risk" ))
totalAverageRisk<- nrow(subset(risk, category= "Average risk" ))
Summary<- c(totalHighRisk,totalAverageRisk)
stat_ratio<- stat(ratio)
library(ggplot2)
ggplot(ratio, aes(x=ratio,after_stat(density)))+
geom_histogram()+
geom_density()+
geom_vline(xintercept = 5)
return(Summary, stat_ratio)
}
my_chol(df,mean)
my_chol <- function(df, stat){
n <- nrow(df)
total <- numeric(n)
ratio <- numeric(n)
risk <- character(n)
for (i in 1:n){
total[i] <- df$hdl[i] + df$ldl[i] + 0.2 * df$trigl[i]
ratio[i] <- total[i] / df$hdl[i]
if (ratio[i] > 5){
risk[i] <- "High risk"
} else {
risk[i] <- "Average risk"
}
}
# Count risk groups
totalHighRisk <- sum(risk == "High risk")
totalAverageRisk <- sum(risk == "Average risk")
Summary <- c(HighRisk = totalHighRisk, AverageRisk = totalAverageRisk)
# Apply statistic
stat_ratio <- stat(ratio)
# Plot
library(ggplot2)
ggplot(data.frame(ratio = ratio), aes(x = ratio, after_stat(density))) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_density(color = "red") +
geom_vline(xintercept = 5, linetype = "dashed", color = "blue")
return(list(Summary = Summary, Stat = stat_ratio))
}
my_chol(df,mean)
my_chol <- function(df, stat){
n <- nrow(df)
total <- NULL
ratio <- NULL
risk <- NULL
for (i in 1:n){
total[i] <- df$hdl[i] + df$ldl[i] + 0.2 * df$trigl[i]
ratio[i] <- total[i] / df$hdl[i]
if (ratio[i] > 5){
risk[i] <- "High risk"
} else {
risk[i] <- "Average risk"
}
}
# Count risk groups
totalHighRisk <- sum(risk == "High risk")
totalAverageRisk <- sum(risk == "Average risk")
Summary <- table(result)
# Apply statistic
stat_ratio <- stat(ratio)
# Plot
hist(ratio,freq=FALSE)
lines(density(ratio),col="cornflowerblue",lwd=2)
abline(v=5,lty=2,col="firebrick",lwd=2)
my_list <- list(summary=summary, stat_ratio=stat_ratio) ## 1/2 mark
return(my_list)
}
my_chol(df,mean)
#NaudeME44038690_SmallTest5_ResearchAssignment
rm(list=ls())
cat("\014")
setwd("C:\Users\marli\OneDrive\NWU\Bsc Business Analytics\_3rd Year\STTN326\Assignment\Naude_44038690_SmallTest5ResearchAssignment")
#NaudeME44038690_SmallTest5_ResearchAssignment
rm(list=ls())
cat("\014")
setwd("C:\\Users\\marli\\OneDrive\\NWU\\Bsc Business Analytics\\_3rd Year\\STTN326\\Assignment\\Naude_44038690_SmallTest5ResearchAssignment")
#Read in data
weather <- read.csv("weather_data.csv")
#convert date_time to make it usefull for time series
weather$Date_Time<- as.POSIXct(weather$Date_Time, format- "%Y-%m-%d %H:%M:%S")
#convert date_time to make it usefull for time series
weather$Date_Time<- as.POSIXct(weather$Date_Time, format= "%Y-%m-%d %H:%M:%S")
#filter data to get San Diego
city_data_SD<- subset(weather, Location == "San Diego")
city_data_SD<- city_data_SD[order(city_data_SD$Date_Time),]
city_temp_SD<- city_data_SD[,c("Date_Time","Temperature_C")]
nrow(city_temp_SD)#check if we have enough observations. We need at least more than 3000
View(city_temp_SD)
weather <- read.csv("weather_data.csv")
#convert date_time to make it usefull for time series
weather$Date_Time<- as.POSIXct(weather$Date_Time, format= "%Y-%m-%d %H:%M:%S")
#filter data to get San Diego
city_data_SD<- subset(weather, Location == "San Diego")
city_data_SD<- city_data_SD[order(city_data_SD$Date_Time),]
city_temp_SD<- city_data_SD[,c("Date_Time","Temperature_C")]
nrow(city_temp_SD)#check if we have enough observations. We need at least more than 300
View(city_data_SD)
View(city_temp_SD)
install.packages("tseries")
library(tseries)
install.packages("urca")
library(urca)
install.packages("forecast")
library(forecast)
install.packages("lubridate")
library(ggplot2)
library(lubridate)
library(dplyr)
myts<- ts(city_temp_SD$Temperature_C, frequency = 24)
plot(city_temp_SD$Date_Time,city_temp_SD$Temperature_C, col="lightpink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
#Too many observations thus lowering it to 500
sub_data_Sd <- city_temp_SD[1:500, ]
plot(sub_data_Sd$Date_Time,sub_data_Sd$Temperature_C, col="lightpink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
daily_temp <- city_data_SD %>%
mutate(Date = as.Date(Date_Time)) %>%
group_by(Date) %>%
summarise(Avg_Temp = mean(Temperature_C, na.rm=TRUE))
plot(daily_temp$Date_Time,daily_temp$Temperature_C, col="lightpink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
daily_temp <- city_data_SD %>%
mutate(Date = as.Date(Date_Time)) %>%
group_by(Date) %>%
summarise(Avg_Temp = mean(Temperature_C, na.rm=TRUE))
plot(daily_temp$Date_Time,daily_temp$Temperature_C, col="lightpink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
#Question 1
plot(daily_temp$Date_Time,daily_temp$Avg_Temp, col="lightpink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
plot(daily_temp$Date,daily_temp$Avg_Temp, col="lightpink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
city_6h <- city_data_SD %>%
mutate(DateTime6h = floor_date(Date_Time, unit = "6 hours")) %>%
group_by(DateTime6h) %>%
summarise(Avg_Temp = mean(Temperature_C, na.rm = TRUE))
sub_hourly <- city_data_SD[seq(1, nrow(city_data_SD), by = 10), ]
View(sub_hourly)
#Too many observations thus sampling the hours
sub_hourly <- city_temp_SD[seq(1, nrow(city_temp_SD), by = 10), ]
plot(sub_hourly$Date,sub_hourly$Avg_Temp, col="pink",
main= "San Diego Tempreture",
xlab="Date",
ylab= "Tempreture (°C)")
rm(list=ls())
cat("\014")
setwd("C:\\Users\\marli\\OneDrive\\NWU\\Bsc Business Analytics\\_3rd Year\\STTN326\\Assignment\\Naude_44038690_SmallTest5ResearchAssignment")
#libraries
#Read in data
temp_Potch<-read.csv("potchefstroom_temperature.csv")
#Question 1
plot(temp_Potch, main="Temperature for Potchefstroom", ylab="Temperature", xlab="Date")
View(temp_Potch)
head(temp_Potch)
temps <- as.numeric(temp_Potch$Temperature_C)
temps_ts <- ts(temps, start = c(2024, 1), frequency = 365)
#Question 1
plot(temps_ts, main="Temperature for Potchefstroom", ylab="Temperature", xlab="Date")
#Question 1
plot(temps_ts, main="Temperature for Potchefstroom", ylab="Temperature", xlab="Date", colour="violetred1")
#Question 1
plot(temps_ts, main="Temperature for Potchefstroom", ylab="Temperature", xlab="Date", colour="violetred1")
#Question 1
plot(temps_ts, main="Temperature for Potchefstroom", ylab="Temperature", xlab="Date", col="violetred1")
temp_London<-read.csv("london_temperature.csv")
head(temp_Potch)
#Convert data into a time series
temps <- as.numeric(temp_London$Temperature_C)
temps_ts <- ts(temps, start = c(2024, 1), frequency = 365)
#Question 1
plot(temps_ts, main="Temperature for London", ylab="Temperature", xlab="Date", col="violetred1")
temp_London<-read.csv("london_temperature.csv")
head(temp_Potch)
#Convert data into a time series
temps <- as.numeric(temp_London$Temperature_C)
temps_ts <- ts(temps, start = c(2024, 1), frequency = 365)
#Question 1
plot(temps_ts, main="Temperature for London", ylab="Temperature", xlab="Date", col="violetred1")
#Question 2
#2.1
(adf_test <- adf.test(temp_ts))
#Question 2
#2.1
(adf_test <- adf.test(temps_ts))
plot(detrend,main="Detrended Temperature for London", ylab="Temperature", xlab="Date", col="violetred1")
time<- 1:length(temps_ts)
mylm<- lm(temps_ts~time)
detrend<- resid(mylm)
plot(detrend,main="Detrended Temperature for London", ylab="Temperature", xlab="Date", col="violetred1")
time<- 1:length(temps_ts)
mylm<- lm(temps_ts~time)
detrend<- resid(mylm)
plot(detrend,main="Detrended Temperature for London", ylab="Residuals", col="violetred2")
diff_temp <- diff(temps_ts)
plot(diff_temp, main="Differenced Temperature", col= "violetred3")
log_temp <- log(temp_ts)
log_temp <- log(temps_ts)
diff_log_temp <- diff(log_temp)
plot(diff_log_temp, main="Log-Differenced Temperature",, col= "violetred4")
myrw<- ur.df(temps_ts, type="none", selectlags = "AIC")
summary(myrw)
myrwd<- ur.df(temps_ts, type="drift", selectlags = "AIC")
summary(myrwd)
acf(diff_temp, main="ACF of Temperature")
#Question 3
#will use the diffirencing model since it gave stationary results
acf(temps_ts, main="ACF of Temperature")
#Question 3
#will use the diffirencing model since it gave stationary results
acf(diff_temp, main="ACF of Temperature")
#Question 3
#will use the diffirencing model since it gave stationary results
acf(diff_temp, main="ACF of Temperature",col= "violetred")
pacf(diff_temp, main="PACF of Temperature",col= "deeppink")
pacf(temps_ts, main="PACF of Temperature",col= "deeppink")
#Question 3
#will use the diffirencing model since it gave stationary results
acf(temps_ts, main="ACF of Temperature",col= "violetred")
pacf(temps_ts, main="PACF of Temperature",col= "deeppink")
#3.3
fit <- auto.arima(temps_ts)
res <- residuals(fit)
acf(res, main = "ACF of Residuals")
fit <- auto.arima(diff_temp )
res <- residuals(fit)
acf(res, main = "ACF of Residuals")
Box.test(res, lag = 20, type = "Ljung-Box")
fit <- auto.arima(diff_temp)
res <- residuals(fit)
acf(res, main = "ACF of Residuals")
Box.test(res, lag = 20, type = "Ljung-Box")#since it considered a small sample
acf(res, main = "ACF of Residuals",col= "deeppink1")
fit <- auto.arima(temps_ts)
summary(fit)
#MLE
fit_mle <- auto.arima(temps_ts, method = "ML")
#MLE
(fit_mle <- auto.arima(temps_ts, method = "ML"))
qqplot(res)
qqnorm(res)
qqline(res)
#Question 5
#5.1
(fc <- forecast(fit, h=20))
#5.2
autoplot(fc)
